Objective:
This document defines the reference architecture and behavioral standards for Kubernetes Scaling Jobs (KSJ) used for asynchronous message processing in our platform. It outlines how we prefer a KSJ to function, handles edge cases, and defines default configurations for KEDA, SQS, and job lifecycle.


Summary
1) A Kubernetes Scaling Job (KSJ) is designed to:
2) Dynamically scale based on queue depth using KEDA
3) Process messages from SQS
4) Ensure messages are reliably handled, retried if needed, and never lost silently
5) Provide observability through structured logs
6) Be resilient to failures and handle graceful shutdowns


updated summary:
This KSJ sample app is designed to:

1) Process a single message from SQS per job execution
2) Use KEDA to dynamically scale jobs based on SQS queue depth
3) Extend message visibility timeout dynamically during long-running processing
4) Handle SIGTERM signals gracefully to avoid silent message loss
5) Provide structured logs compatible with Fluent Bit ‚Üí Splunk or other observability pipelines

Reference Workflow:
***
+-------------+ +------------+ +----------------+
| Developer/API | -----> | S3 | -----> | SQS |
+-------------+ +------------+ +----------------+
|
v
+---------------------------+
| KEDA ScaledObject |
| (SQS Trigger) |
+---------------------------+
|
v
+--------------------------+
| K8s ScaledJob (KSJ)|
+--------------------------+
|
+------------------------+-------------------+-------------------------+
| | |
Read SQS Msg Execute Business Logic Log + Retry Policy
| | |
On Success On Success On Failure
| | |
Delete SQS Msg Terminate Pod Let message timeout (remain in
queue)



    +------------------------------+
          |     Kubernetes Scaling Job   |
          |    (KSJ Worker Container)    |
          +------------------------------+
                            |
                            v
             +------------------------------+
             |  Read Message from SQS       |  ‚Üê Visibility Timeout Starts
             +------------------------------+
                            |
                            v
             +------------------------------+
             |  Start Background Thread     |
             |  to Extend Visibility        |
             +------------------------------+
                            |
                            v
             +------------------------------+
             |  Execute Job Logic           |
             |  (e.g. process order, image) |
             +------------------------------+
                            |
            / \                             \
           /   \                             \ SIGTERM received?
   Success     Failure                        ‚Üí Set shutdown_event
     |             |                          ‚Üí Do NOT delete message
     |             v
     |     +-----------------------------+
     |     |  Log Error, Let Timeout Expire
     |     +-----------------------------+
     |
     v
+-----------------------------+
|   Delete Message from SQS   |
+-----------------------------+

Implementation Guidelines
1. Message Visibility Timeout:
The sample KSJ worker uses Amazon SQS visibility timeout to ensure messages are not processed by more than one worker simultaneously. This section outlines how timeouts are configured and dynamically extended during job execution.
| Feature               | Recommendation                                                        |
| --------------------- | --------------------------------------------------------------------- |
| **Initial Timeout**   | 30‚Äì60 seconds (via `ReceiveMessage`)                                  |
| **Dynamic Extension** | Use if job duration is variable or long                               |
| **Maximum Timeout**   | Should match max expected processing time (e.g., 10 minutes)          |
| **On Failure**        | Don‚Äôt delete message ‚Äì let it become visible again after timeout      |


Initial Timeout (30 seconds)

```VISIBILITY_TIMEOUT = int(os.getenv("INITIAL_VISIBILITY_TIMEOUT", 30))  # Default 30s

response = sqs.receive_message(
    QueueUrl=QUEUE_URL,
    MaxNumberOfMessages=1,
    WaitTimeSeconds=10,
    VisibilityTimeout=VISIBILITY_TIMEOUT  # <-- Initial visibility timeout
)
```
Recommendation:
Set the initial visibility timeout between 30‚Äì60 seconds ‚Äî long enough for most short jobs, but short enough to allow retries if the job crashes quickly.

Dynamic Extension:
```
EXTEND_INTERVAL = int(os.getenv("VISIBILITY_EXTENSION_INTERVAL", 10))  # every 10s
EXTEND_BY = int(os.getenv("EXTEND_BY", 30))  # extend by 30s

def extend_visibility_timeout():
    while not shutdown_event.is_set():
        time.sleep(EXTEND_INTERVAL)
        if receipt_handle:
            try:
                logging.info(f"Extending visibility timeout by {EXTEND_BY}s")
                sqs.change_message_visibility(
                    QueueUrl=QUEUE_URL,
                    ReceiptHandle=receipt_handle,
                    VisibilityTimeout=EXTEND_BY
                )
            except Exception as e:
                logging.error(f"Failed to extend visibility timeout: {e}")
```
A background thread runs every EXTEND_INTERVAL to extend the timeout while the job is still working.
Recommendation for Dynamic Extension:
We recommend dynamic visibility timeout only if:

1) Our job has variable processing times, and static timeouts would be inefficient

2) We want faster recovery from job crashes (e.g., via retry within 30s instead of waiting full max timeout)

3) We are not using FIFO queues with deduplication delay issues

4) If Our job always takes 60 seconds, we may skip dynamic extension and just set VisibilityTimeout=60.

On Failure ‚Äì Do Not Delete Message
```
try:
    process_message(message_body)

    if shutdown_event.is_set():
        logging.warning("Job interrupted. Message will return to queue.")
    else:
        logging.info("Deleting message from queue")
        sqs.delete_message(
            QueueUrl=QUEUE_URL,
            ReceiptHandle=receipt_handle
        )

except Exception as e:
    logging.error(f"Job failed with exception: {e}")
    # Message is NOT deleted ‚Äî becomes visible again after timeout
```
If the job crashes or is interrupted (SIGTERM), the message is left in SQS and reappears after timeout.



2) Read Message ‚Üí Process Message ‚Üí  Delete Message
following code snippet is just a sample app reference

 a. Read 1 Message from SQS
```
response = sqs.receive_message(
    QueueUrl=QUEUE_URL,
    MaxNumberOfMessages=1,  # üëà Reads only one message per job
    WaitTimeSeconds=10,
    VisibilityTimeout=VISIBILITY_TIMEOUT
)
```

This is the message retrieval step.

MaxNumberOfMessages=1: Ensures one job handles one message.

VisibilityTimeout: Ensures the message becomes invisible to others while the job is processing it.

Note: This makes the job scalable, isolated, and avoids concurrent processing of the same message.

b. Process the Message
following code snippet is just a sample app reference
```
def process_message(message_body, receipt_handle):
    logging.info(f"Started processing message: {message_body}")

    total_processing_time = 60  # Total simulated job time in seconds
    elapsed = 0

    while elapsed < total_processing_time and not shutdown_event.is_set():
        time.sleep(EXTEND_INTERVAL)  # ‚è±Ô∏è Sleep for configured interval
        elapsed += EXTEND_INTERVAL

        logging.info(f"Processed {elapsed}/{total_processing_time} seconds")

        try:
            logging.info(f"Extending visibility timeout by {EXTEND_BY}s")
            sqs.change_message_visibility(
                QueueUrl=QUEUE_URL,
                ReceiptHandle=receipt_handle,
                VisibilityTimeout=EXTEND_BY
            )
        except Exception as e:
            logging.error(f"Failed to extend visibility timeout: {e}")

    if shutdown_event.is_set():
        logging.warning("Processing was interrupted by shutdown.")
    else:
        logging.info("Finished processing message")

```

here we will be having our code logic.

| Config Var        | Usage in Function                                        |
| ----------------- | -------------------------------------------------------- |
| `EXTEND_INTERVAL` | Used as sleep duration in the loop ‚Äî how often to extend |
| `EXTEND_BY`       | Duration to extend visibility on each API call           |

c. Delete the Message (Only on Success)
```
if shutdown_event.is_set():
    logging.warning("Job interrupted. Message will return to queue.")
else:
    logging.info("Deleting message from queue")
    sqs.delete_message(
        QueueUrl=QUEUE_URL,
        ReceiptHandle=receipt_handle
    )
```


If processing completed successfully and job was not interrupted, the message is explicitly deleted from the queue.

This prevents it from being reprocessed.

Note: Only delete after successful processing.

3) Handling SIGTERM:
When Kubernetes terminates a pod (e.g., scaling down or job completion), it sends a SIGTERM signal to give the container a chance to shut down cleanly before forcibly killing it with SIGKILL.

Without handling SIGTERM:

> our worker might exit mid-processing

> The message might get lost or never reappear (if deleted too early)

Every long-running loop (like the message processor or visibility extender) checks shutdown_event.is_set():

```
while elapsed < total_processing_time and not shutdown_event.is_set():
```
As soon as SIGTERM is received, shutdown_event is set
```
while not shutdown_event.is_set():
```
All loops will gracefully break out, log exit, and stop processing

Our Logic should integrates graceful SIGTERM handling correctly:

> Catches the signal

> Signals all threads to stop

> Skips deleting the message on early termination

4)Logging 
All logs must be written to stdout

Use structured log format:

```
2025-06-23T10:00:00Z | INFO | Processing message: {messageId: abc123}
2025-06-23T10:00:15Z | WARN | SIGTERM received, exiting
2025-06-23T10:00:20Z | ERROR | Job failed with: TimeoutError
```
Required fields:

message_id, job_id, retry_count, duration, status, error

5) Keda Configurations:
| Setting                       | Recommended Default             | Description                            |
| ----------------------------- | ------------------------------- | -------------------------------------- |
| `pollingInterval`             | `10s`                           | Frequency of checking SQS for messages |
| `cooldownPeriod`              | `30s`                           | Time to wait before scaling down jobs  |
| `minReplicaCount`             | `0`                             | No idle jobs running                   |
| `maxReplicaCount`             | Set to match queue scale limits |                                        |
| `scaledJob.concurrencyPolicy` | `Forbid`                        | Prevent parallel jobs on same message  |
| `jobTargetRef.backoffLimit`   | `3`                             | Number of retries on job failure       |

```
apiVersion: keda.sh/v1alpha1
kind: ScaledJob
metadata:
  name: my-sqs-worker
spec:
  pollingInterval: 10
  successfulJobsHistoryLimit: 2
  failedJobsHistoryLimit: 2
  maxReplicaCount: 10
  jobTargetRef:
    backoffLimit: 3
    parallelism: 1
  triggers:
    - type: aws-sqs-queue
      metadata:
        queueURL: https://sqs.us-east-1.amazonaws.com/1234/my-queue
        awsRegion: us-east-1

```
